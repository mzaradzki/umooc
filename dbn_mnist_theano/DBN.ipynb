{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams\n",
    "\n",
    "from logistic_sgd import LogisticRegression, load_data\n",
    "from mlp import HiddenLayer\n",
    "from rbm import RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DBN(object):\n",
    "    \"\"\"Deep Belief Network\n",
    "\n",
    "    A deep belief network is obtained by stacking several RBMs on top of each\n",
    "    other. The hidden layer of the RBM at layer `i` becomes the input of the\n",
    "    RBM at layer `i+1`. The first layer RBM gets as input the input of the\n",
    "    network, and the hidden layer of the last RBM represents the output. When\n",
    "    used for classification, the DBN is treated as a MLP, by adding a logistic\n",
    "    regression layer on top.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, numpy_rng, theano_rng=None, n_ins=784,\n",
    "                 hidden_layers_sizes=[500, 500], n_outs=10):\n",
    "        \"\"\"This class is made to support a variable number of layers.\n",
    "\n",
    "        :type numpy_rng: numpy.random.RandomState\n",
    "        :param numpy_rng: numpy random number generator used to draw initial\n",
    "                    weights\n",
    "\n",
    "        :type theano_rng: theano.tensor.shared_randomstreams.RandomStreams\n",
    "        :param theano_rng: Theano random generator; if None is given one is\n",
    "                           generated based on a seed drawn from `rng`\n",
    "\n",
    "        :type n_ins: int\n",
    "        :param n_ins: dimension of the input to the DBN\n",
    "\n",
    "        :type hidden_layers_sizes: list of ints\n",
    "        :param hidden_layers_sizes: intermediate layers size, must contain\n",
    "                               at least one value\n",
    "\n",
    "        :type n_outs: int\n",
    "        :param n_outs: dimension of the output of the network\n",
    "        \"\"\"\n",
    "\n",
    "        self.sigmoid_layers = []\n",
    "        self.rbm_layers = []\n",
    "        self.params = []\n",
    "        self.n_layers = len(hidden_layers_sizes)\n",
    "\n",
    "        assert self.n_layers > 0\n",
    "\n",
    "        if not theano_rng:\n",
    "            theano_rng = MRG_RandomStreams(numpy_rng.randint(2 ** 30))\n",
    "\n",
    "        # allocate symbolic variables for the data\n",
    "\n",
    "        # the data is presented as rasterized images\n",
    "        self.x = T.matrix('x')\n",
    "\n",
    "        # the labels are presented as 1D vector of [int] labels\n",
    "        self.y = T.ivector('y')\n",
    "        # end-snippet-1\n",
    "        # The DBN is an MLP, for which all weights of intermediate\n",
    "        # layers are shared with a different RBM.  We will first\n",
    "        # construct the DBN as a deep multilayer perceptron, and when\n",
    "        # constructing each sigmoidal layer we also construct an RBM\n",
    "        # that shares weights with that layer. During pretraining we\n",
    "        # will train these RBMs (which will lead to chainging the\n",
    "        # weights of the MLP as well) During finetuning we will finish\n",
    "        # training the DBN by doing stochastic gradient descent on the\n",
    "        # MLP.\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            # construct the sigmoidal layer\n",
    "\n",
    "            # the size of the input is either the number of hidden\n",
    "            # units of the layer below or the input size if we are on\n",
    "            # the first layer\n",
    "            if i == 0:\n",
    "                input_size = n_ins\n",
    "            else:\n",
    "                input_size = hidden_layers_sizes[i - 1]\n",
    "\n",
    "            # the input to this layer is either the activation of the\n",
    "            # hidden layer below or the input of the DBN if you are on\n",
    "            # the first layer\n",
    "            if i == 0:\n",
    "                layer_input = self.x\n",
    "            else:\n",
    "                layer_input = self.sigmoid_layers[-1].output\n",
    "\n",
    "            sigmoid_layer = HiddenLayer(rng=numpy_rng,\n",
    "                                        input=layer_input,\n",
    "                                        n_in=input_size,\n",
    "                                        n_out=hidden_layers_sizes[i],\n",
    "                                        activation=T.nnet.sigmoid)\n",
    "\n",
    "            # add the layer to our list of layers\n",
    "            self.sigmoid_layers.append(sigmoid_layer)\n",
    "\n",
    "            # its arguably a philosophical question...  but we are\n",
    "            # going to only declare that the parameters of the\n",
    "            # sigmoid_layers are parameters of the DBN. The visible\n",
    "            # biases in the RBM are parameters of those RBMs, but not\n",
    "            # of the DBN.\n",
    "            self.params.extend(sigmoid_layer.params)\n",
    "\n",
    "            # Construct an RBM that shared weights with this layer\n",
    "            rbm_layer = RBM(numpy_rng=numpy_rng,\n",
    "                            theano_rng=theano_rng,\n",
    "                            input=layer_input,\n",
    "                            n_visible=input_size,\n",
    "                            n_hidden=hidden_layers_sizes[i],\n",
    "                            W=sigmoid_layer.W,\n",
    "                            hbias=sigmoid_layer.b)\n",
    "            self.rbm_layers.append(rbm_layer)\n",
    "\n",
    "        # We now need to add a logistic layer on top of the MLP\n",
    "        self.logLayer = LogisticRegression(\n",
    "            input=self.sigmoid_layers[-1].output,\n",
    "            n_in=hidden_layers_sizes[-1],\n",
    "            n_out=n_outs)\n",
    "        self.params.extend(self.logLayer.params)\n",
    "\n",
    "        # compute the cost for second phase of training, defined as the\n",
    "        # negative log likelihood of the logistic regression (output) layer\n",
    "        self.finetune_cost = self.logLayer.negative_log_likelihood(self.y)\n",
    "\n",
    "        # compute the gradients with respect to the model parameters\n",
    "        # symbolic variable that points to the number of errors made on the\n",
    "        # minibatch given by self.x and self.y\n",
    "        self.errors = self.logLayer.errors(self.y)\n",
    "\n",
    "    def pretraining_functions(self, train_set_x, batch_size, k):\n",
    "        '''Generates a list of functions, for performing one step of\n",
    "        gradient descent at a given layer. The function will require\n",
    "        as input the minibatch index, and to train an RBM you just\n",
    "        need to iterate, calling the corresponding function on all\n",
    "        minibatch indexes.\n",
    "\n",
    "        :type train_set_x: theano.tensor.TensorType\n",
    "        :param train_set_x: Shared var. that contains all datapoints used\n",
    "                            for training the RBM\n",
    "        :type batch_size: int\n",
    "        :param batch_size: size of a [mini]batch\n",
    "        :param k: number of Gibbs steps to do in CD-k / PCD-k\n",
    "\n",
    "        '''\n",
    "\n",
    "        # index to a [mini]batch\n",
    "        index = T.lscalar('index')  # index to a minibatch\n",
    "        learning_rate = T.scalar('lr')  # learning rate to use\n",
    "\n",
    "        # begining of a batch, given `index`\n",
    "        batch_begin = index * batch_size\n",
    "        # ending of a batch given `index`\n",
    "        batch_end = batch_begin + batch_size\n",
    "\n",
    "        pretrain_fns = []\n",
    "        for rbm in self.rbm_layers:\n",
    "\n",
    "            # get the cost and the updates list\n",
    "            # using CD-k here (persisent=None) for training each RBM.\n",
    "            # TODO: change cost function to reconstruction error\n",
    "            cost, updates = rbm.get_cost_updates(learning_rate,\n",
    "                                                 persistent=None, k=k)\n",
    "\n",
    "            # compile the theano function\n",
    "            fn = theano.function(\n",
    "                inputs=[index, theano.In(learning_rate, value=0.1)],\n",
    "                outputs=cost,\n",
    "                updates=updates,\n",
    "                givens={\n",
    "                    self.x: train_set_x[batch_begin:batch_end]\n",
    "                }\n",
    "            )\n",
    "            # append `fn` to the list of functions\n",
    "            pretrain_fns.append(fn)\n",
    "\n",
    "        return pretrain_fns\n",
    "\n",
    "    def build_finetune_functions(self, datasets, batch_size, learning_rate):\n",
    "        '''Generates a function `train` that implements one step of\n",
    "        finetuning, a function `validate` that computes the error on a\n",
    "        batch from the validation set, and a function `test` that\n",
    "        computes the error on a batch from the testing set\n",
    "\n",
    "        :type datasets: list of pairs of theano.tensor.TensorType\n",
    "        :param datasets: It is a list that contain all the datasets;\n",
    "                        the has to contain three pairs, `train`,\n",
    "                        `valid`, `test` in this order, where each pair\n",
    "                        is formed of two Theano variables, one for the\n",
    "                        datapoints, the other for the labels\n",
    "        :type batch_size: int\n",
    "        :param batch_size: size of a minibatch\n",
    "        :type learning_rate: float\n",
    "        :param learning_rate: learning rate used during finetune stage\n",
    "\n",
    "        '''\n",
    "\n",
    "        (train_set_x, train_set_y) = datasets[0]\n",
    "        (valid_set_x, valid_set_y) = datasets[1]\n",
    "        (test_set_x, test_set_y) = datasets[2]\n",
    "\n",
    "        # compute number of minibatches for training, validation and testing\n",
    "        n_valid_batches = valid_set_x.get_value(borrow=True).shape[0]\n",
    "        n_valid_batches //= batch_size\n",
    "        n_test_batches = test_set_x.get_value(borrow=True).shape[0]\n",
    "        n_test_batches //= batch_size\n",
    "\n",
    "        index = T.lscalar('index')  # index to a [mini]batch\n",
    "\n",
    "        # compute the gradients with respect to the model parameters\n",
    "        gparams = T.grad(self.finetune_cost, self.params)\n",
    "\n",
    "        # compute list of fine-tuning updates\n",
    "        updates = []\n",
    "        for param, gparam in zip(self.params, gparams):\n",
    "            updates.append((param, param - gparam * learning_rate))\n",
    "\n",
    "        train_fn = theano.function(\n",
    "            inputs=[index],\n",
    "            outputs=self.finetune_cost,\n",
    "            updates=updates,\n",
    "            givens={\n",
    "                self.x: train_set_x[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ],\n",
    "                self.y: train_set_y[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        test_score_i = theano.function(\n",
    "            [index],\n",
    "            self.errors,\n",
    "            givens={\n",
    "                self.x: test_set_x[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ],\n",
    "                self.y: test_set_y[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        valid_score_i = theano.function(\n",
    "            [index],\n",
    "            self.errors,\n",
    "            givens={\n",
    "                self.x: valid_set_x[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ],\n",
    "                self.y: valid_set_y[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Create a function that scans the entire validation set\n",
    "        def valid_score():\n",
    "            return [valid_score_i(i) for i in range(n_valid_batches)]\n",
    "\n",
    "        # Create a function that scans the entire test set\n",
    "        def test_score():\n",
    "            return [test_score_i(i) for i in range(n_test_batches)]\n",
    "\n",
    "        return train_fn, valid_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_DBN(finetune_lr=0.1, pretraining_epochs=100,\n",
    "             pretrain_lr=0.01, k=1, training_epochs=1000,\n",
    "             dataset='mnist.pkl.gz', batch_size=10):\n",
    "    \"\"\"\n",
    "    Demonstrates how to train and test a Deep Belief Network.\n",
    "\n",
    "    This is demonstrated on MNIST.\n",
    "\n",
    "    :type finetune_lr: float\n",
    "    :param finetune_lr: learning rate used in the finetune stage\n",
    "    :type pretraining_epochs: int\n",
    "    :param pretraining_epochs: number of epoch to do pretraining\n",
    "    :type pretrain_lr: float\n",
    "    :param pretrain_lr: learning rate to be used during pre-training\n",
    "    :type k: int\n",
    "    :param k: number of Gibbs steps in CD/PCD\n",
    "    :type training_epochs: int\n",
    "    :param training_epochs: maximal number of iterations ot run the optimizer\n",
    "    :type dataset: string\n",
    "    :param dataset: path the the pickled dataset\n",
    "    :type batch_size: int\n",
    "    :param batch_size: the size of a minibatch\n",
    "    \"\"\"\n",
    "\n",
    "    datasets = load_data(dataset)\n",
    "\n",
    "    train_set_x, train_set_y = datasets[0]\n",
    "    valid_set_x, valid_set_y = datasets[1]\n",
    "    test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "\n",
    "    # numpy random generator\n",
    "    numpy_rng = numpy.random.RandomState(123)\n",
    "    print('... building the model')\n",
    "    # construct the Deep Belief Network\n",
    "    dbn = DBN(numpy_rng=numpy_rng, n_ins=28 * 28,\n",
    "              hidden_layers_sizes=[1000, 500, 250, 100, 50],\n",
    "              n_outs=10)\n",
    "\n",
    "    # start-snippet-2\n",
    "    #########################\n",
    "    # PRETRAINING THE MODEL #\n",
    "    #########################\n",
    "    print('... getting the pretraining functions')\n",
    "    pretraining_fns = dbn.pretraining_functions(train_set_x=train_set_x,\n",
    "                                                batch_size=batch_size,\n",
    "                                                k=k)\n",
    "\n",
    "    print('... pre-training the model')\n",
    "    start_time = timeit.default_timer()\n",
    "    # Pre-train layer-wise\n",
    "    for i in range(dbn.n_layers):\n",
    "        # go through pretraining epochs\n",
    "        for epoch in range(pretraining_epochs):\n",
    "            # go through the training set\n",
    "            c = []\n",
    "            for batch_index in range(n_train_batches):\n",
    "                c.append(pretraining_fns[i](index=batch_index,\n",
    "                                            lr=pretrain_lr))\n",
    "            print('Pre-training layer %i, epoch %d, cost ' % (i, epoch), end=' ')\n",
    "            print(numpy.mean(c, dtype='float64'))\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    # end-snippet-2\n",
    "    print('The pretraining code for file ' + 'os.path.split(__file__)[1]' +\n",
    "          ' ran for %.2fm' % ((end_time - start_time) / 60.), file=sys.stderr)\n",
    "    ########################\n",
    "    # FINETUNING THE MODEL #\n",
    "    ########################\n",
    "\n",
    "    # get the training, validation and testing function for the model\n",
    "    print('... getting the finetuning functions')\n",
    "    train_fn, validate_model, test_model = dbn.build_finetune_functions(\n",
    "        datasets=datasets,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=finetune_lr\n",
    "    )\n",
    "\n",
    "    print('... finetuning the model')\n",
    "    # early-stopping parameters\n",
    "\n",
    "    # look as this many examples regardless\n",
    "    patience = 4 * n_train_batches\n",
    "\n",
    "    # wait this much longer when a new best is found\n",
    "    patience_increase = 2.\n",
    "\n",
    "    # a relative improvement of this much is considered significant\n",
    "    improvement_threshold = 0.995\n",
    "\n",
    "    # go through this many minibatches before checking the network on\n",
    "    # the validation set; in this case we check every epoch\n",
    "    validation_frequency = min(n_train_batches, patience / 2)\n",
    "\n",
    "    best_validation_loss = numpy.inf\n",
    "    test_score = 0.\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    done_looping = False\n",
    "    epoch = 0\n",
    "    \n",
    "    best_iter = -1\n",
    "    while (epoch < training_epochs) and (not done_looping):\n",
    "        epoch = epoch + 1\n",
    "        for minibatch_index in range(n_train_batches):\n",
    "\n",
    "            train_fn(minibatch_index)\n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "\n",
    "            if (iter + 1) % validation_frequency == 0:\n",
    "\n",
    "                validation_losses = validate_model()\n",
    "                this_validation_loss = numpy.mean(validation_losses, dtype='float64')\n",
    "                print('epoch %i, minibatch %i/%i, validation error %f %%' % (\n",
    "                    epoch,\n",
    "                    minibatch_index + 1,\n",
    "                    n_train_batches,\n",
    "                    this_validation_loss * 100.\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # if we got the best validation score until now\n",
    "                if this_validation_loss < best_validation_loss:\n",
    "\n",
    "                    # improve patience if loss improvement is good enough\n",
    "                    if (this_validation_loss < best_validation_loss *\n",
    "                            improvement_threshold):\n",
    "                        patience = max(patience, iter * patience_increase)\n",
    "\n",
    "                    # save best validation score and iteration number\n",
    "                    best_validation_loss = this_validation_loss\n",
    "                    best_iter = iter\n",
    "\n",
    "                    # test it on the test set\n",
    "                    test_losses = test_model()\n",
    "                    test_score = numpy.mean(test_losses, dtype='float64')\n",
    "                    print(('     epoch %i, minibatch %i/%i, test error of '\n",
    "                           'best model %f %%') %\n",
    "                          (epoch, minibatch_index + 1, n_train_batches,\n",
    "                          test_score * 100.))\n",
    "\n",
    "            if patience <= iter:\n",
    "                done_looping = True\n",
    "                break\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    '''print(('Optimization complete with best validation score of %f %%, '\n",
    "           'obtained at iteration %i, '\n",
    "           'with test performance %f %%'\n",
    "           ) % (best_validation_loss * 100., best_iter + 1, test_score * 100.))\n",
    "    print('The fine tuning code for file ' + 'os.path.split(__file__)[1]' +\n",
    "          ' ran for %.2fm' % ((end_time - start_time) / 60.), file=sys.stderr)'''\n",
    "    \n",
    "    return dbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n",
      "... getting the pretraining functions\n",
      "... pre-training the model\n",
      "Pre-training layer 0, epoch 0, cost  -126.359804122\n",
      "Pre-training layer 0, epoch 1, cost  -100.508592642\n",
      "Pre-training layer 0, epoch 2, cost  -93.9698730449\n",
      "Pre-training layer 0, epoch 3, cost  -90.3339596796\n",
      "Pre-training layer 1, epoch 0, cost  -415.981320272\n",
      "Pre-training layer 1, epoch 1, cost  -373.392307218\n",
      "Pre-training layer 1, epoch 2, cost  -362.693806549\n",
      "Pre-training layer 1, epoch 3, cost  -356.868296996\n",
      "Pre-training layer 2, epoch 0, cost  -69.6013400704\n",
      "Pre-training layer 2, epoch 1, cost  -49.6928573833\n",
      "Pre-training layer 2, epoch 2, cost  -46.2851750451\n",
      "Pre-training layer 2, epoch 3, cost  -44.4802378363\n",
      "Pre-training layer 3, epoch 0, cost  -115.195390425\n",
      "Pre-training layer 3, epoch 1, cost  -97.7894743408\n",
      "Pre-training layer 3, epoch 2, cost  -93.2719895269\n",
      "Pre-training layer 3, epoch 3, cost  -91.0569289399\n",
      "Pre-training layer 4, epoch 0, cost  -24.0386392786\n",
      "Pre-training layer 4, epoch 1, cost  -16.6496586427\n",
      "Pre-training layer 4, epoch 2, cost  -14.6227866745\n",
      "Pre-training layer 4, epoch 3, cost  -13.6213028208\n",
      "... getting the finetuning functions\n",
      "... finetuning the model\n",
      "epoch 1, minibatch 781/781, validation error 15.284455 %\n",
      "     epoch 1, minibatch 781/781, test error of best model 15.845353 %\n",
      "epoch 2, minibatch 781/781, validation error 10.767228 %\n",
      "     epoch 2, minibatch 781/781, test error of best model 11.187901 %\n",
      "epoch 3, minibatch 781/781, validation error 8.583734 %\n",
      "     epoch 3, minibatch 781/781, test error of best model 9.124599 %\n",
      "epoch 4, minibatch 781/781, validation error 7.341747 %\n",
      "     epoch 4, minibatch 781/781, test error of best model 7.882612 %\n",
      "epoch 5, minibatch 781/781, validation error 6.550481 %\n",
      "     epoch 5, minibatch 781/781, test error of best model 6.991186 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pretraining code for file os.path.split(__file__)[1] ran for 0.55m\n"
     ]
    }
   ],
   "source": [
    "dbn = test_DBN(finetune_lr=0.1, pretraining_epochs=4,\n",
    "             pretrain_lr=0.01, k=1, training_epochs=5,\n",
    "             dataset='../data/mnist.pkl.gz', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "train_set_x, train_set_y = load_data('../data/mnist.pkl.gz')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def upthendown(V, d1=True, d2=True):\n",
    "    # UP\n",
    "    if d1:\n",
    "        H0 = dbn.rbm_layers[0].propup(V)[-1].eval()\n",
    "        H1 = dbn.rbm_layers[1].propup(H0)[-1].eval()\n",
    "        H2 = dbn.rbm_layers[2].propup(H1)[-1].eval()\n",
    "        H3 = dbn.rbm_layers[3].propup(H2)[-1].eval()\n",
    "        H4 = dbn.rbm_layers[4].propup(H3)[-1].eval()\n",
    "    else:\n",
    "        H0 = dbn.rbm_layers[0].sample_h_given_v(V)[-1].eval()\n",
    "        H1 = dbn.rbm_layers[1].sample_h_given_v(H0)[-1].eval()\n",
    "        H2 = dbn.rbm_layers[2].sample_h_given_v(H1)[-1].eval()\n",
    "        H3 = dbn.rbm_layers[3].sample_h_given_v(H2)[-1].eval()\n",
    "        H4 = dbn.rbm_layers[4].sample_h_given_v(H3)[-1].eval()\n",
    "    # DOWN\n",
    "    if d2: # DOWN deterministic\n",
    "        H3d = dbn.rbm_layers[4].propdown(H4)[-1].eval()\n",
    "        H2d = dbn.rbm_layers[3].propdown(H3d)[-1].eval()\n",
    "        H1d = dbn.rbm_layers[2].propdown(H2d)[-1].eval()\n",
    "        H0d = dbn.rbm_layers[1].propdown(H1d)[-1].eval()\n",
    "        Vd = dbn.rbm_layers[0].propdown(H0d)[-1].eval()\n",
    "    else: # DOWN stochastic\n",
    "        H3d = dbn.rbm_layers[4].sample_v_given_h(H4)[-1].eval()\n",
    "        H2d = dbn.rbm_layers[3].sample_v_given_h(H3d)[-1].eval()\n",
    "        H1d = dbn.rbm_layers[2].sample_v_given_h(H2d)[-1].eval()\n",
    "        H0d = dbn.rbm_layers[1].sample_v_given_h(H1d)[-1].eval()\n",
    "        Vd = dbn.rbm_layers[0].sample_v_given_h(H0d)[-1].eval()\n",
    "    return Vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnC3Ehe84W4gL33G2kP8PI6NkYHSSWSYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4760c7a310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRGKE+P+B35r9z7PnjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4764a82690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V = train_set_x.get_value()[170]\n",
    "Vd = upthendown(V, True, True)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(V.reshape(28,28)*255., cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "plt.imshow(Vd.reshape(28,28)*255., cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
